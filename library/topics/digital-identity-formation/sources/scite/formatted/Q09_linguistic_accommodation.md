---
cluster: 2
query: What evidence exists for linguistic accommodation or entrainment in human-AI
  conversation, and does early accommodation predict continued use?
question_id: Q09
reference_count: 18
source_date: '2026-01-01'
title: Linguistic Accommodation
---

Evidence for linguistic accommodation or entrainment in human-AI conversation

Introduction and conceptual framing

Convergent language styles and cross-cultural alignment

Adaptive dialogue strategies and pacing

Empathy, affect, and perceived social alignment

Domain-specific demonstrations of adaptive conversational style

Evidence that early accommodation may predict continued use

A core question is whether early accommodation (AI adaptation at the initial stages of interaction) influences continued engagement. Several strands of evidence converge on this point, albeit with important caveats:

Notably, there is some nuance in the MI-specific literature: while AI reflections can align with MI principles, researchers report limitations in emotional depth and perceived empathy, suggesting that early accommodation may not automatically translate into durable use unless accompanied by sustained improvements in affective responsiveness and perceived trustworthiness,. Cross-domain evidence on continuance supports the idea that initial positive accommodation supports continued use, but this relationship can be moderated by factors such as cultural fit, perceived empathy, and ongoing conversational quality,,,.
  - Citations: Karve et al. (2025), Zhang et al. (2025), Warjiyono (2025), Ahn et al. (2024), Igwe-Nmaju et al. (2023)

Synthesis: what the evidence implies for linguistic accommodation and its predictive value for continued use

Implications for design and research

Conclusion


## References

1. Ahn, S., Kim, S., Lee, E., Lee, H., Song, E., Song, J., … & Won, J. (2024). How do AI and human users interact? Positioning of AI and human users in customer service. *Text & Talk - An Interdisciplinary Journal of Language Discourse Communication Studies, 45(3), 301-318*.
2. AlAli, R. and Wardat, Y. (2024). Enhancing Classroom Learning: ChatGPT's Integration and Educational Challenges. *International Journal of Religion, 5(6), 971-985*.
3. Bickmore, T., Schulman, D., & Sidner, C. (2013). Automated interventions for multiple health behaviors using conversational agents. *Patient Education and Counseling, 92(2), 142-148*.
4. Brown, A., Kumar, A., Melamed, O., Ahmed, I., Wang, Y., Deza, A., … & Rose, J. (2023). A Motivational Interviewing Chatbot With Generative Reflections for Increasing Readiness to Quit Smoking: Iterative Development Study. *Jmir Mental Health, 10, e49132*.
5. Chang, R. and Wang, H. (2025). Communication Accommodation Between Large Language Models and Users Across Cultures (Student Abstract). *Proceedings of the Aaai Conference on Artificial Intelligence, 39(28), 29331-29333*.
6. Cruz, J., Oliveira, P., & Cação, I. (2023). TEACHING AND LEARNING CALCULUS WITH CHATGPT: BENEFITS AND LIMITATIONS., 1, 456-463.
7. Heston, T. (2023). Safety of Large Language Models in Addressing Depression. *Cureus*.
8. Igwe-Nmaju, C., Gbaja, C., & Ikeh, C. (2023). Redesigning customer experience through AI: A communication-centered approach in telecoms and tech-driven industries. *International Journal of Science and Research Archive, 10(2), 1367-1388*.
9. Karve, Z., Calpey, J., Machado, C., Knecht, M., & Grubb, M. (2025). New Doc on the Block: Scoping Review of AI Systems Delivering Motivational Interviewing for Health Behavior Change (Preprint).
10. Karve, Z., Calpey, J., Machado, C., Knecht, M., & Grubb, M. (2025). New Doc on the Block: Scoping Review of AI Systems Delivering Motivational Interviewing for Health Behavior Change. *Journal of Medical Internet Research, 27, e78417*.
11. Laranjo, L., Dunn, A., Tong, H., Kocaballı, A., Chen, J., Bashir, R., … & Coiera, E. (2018). Conversational agents in healthcare: a systematic review. *Journal of the American Medical Informatics Association, 25(9), 1248-1258*.
12. Rao, T., Deepika, J., Uppala, V., & Swetha, C. (2025). The Rise of Artificial Empathy., 25-54.
13. Ritchie, D., Dowell, N., Tate, T., & Warschauer, M. (2025). From Wandering to Collaboration: Discourse Patterns in Middle School Generative AI Use.
14. Steels, L. (2006). Semiotic Dynamics for Embodied Agents. *Ieee Intelligent Systems, 21(3), 32-38*.
15. Temsah, R., Altamimi, I., Alhasan, K., Temsah, M., & Jamal, A. (2023). Healthcare's New Horizon With ChatGPT's Voice and Vision Capabilities: A Leap Beyond Text. *Cureus*.
16. Warjiyono, W. (2025). AI chatbot quality in customer service: Extending measurement models with conversational capability. *Edelweiss Applied Science and Technology, 9(10), 1416-1436*.
17. Zhang, J., Oh, Y., Lange, P., Yu, Z., & Fukuoka, Y. (2020). Artificial Intelligence Chatbot Behavior Change Model for Designing Artificial Intelligence Chatbots to Promote Physical Activity and a Healthy Diet: Viewpoint. *Journal of Medical Internet Research, 22(9), e22845*.
18. Zhang, K., Luo, J., Huang, Q., Zhang, K., & Du, J. (2025). The Effect of Perceived Interactivity on Continuance Intention to Use AI Conversational Agents: A Two-Stage Hybrid PLS-ANN Approach. *Journal of Theoretical and Applied Electronic Commerce Research, 20(4), 255*.