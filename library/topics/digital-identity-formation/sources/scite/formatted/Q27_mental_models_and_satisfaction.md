---
cluster: 7
query: How do users' mental models of AI capabilities (revealed through first prompts)
  predict satisfaction and continued use?
question_id: Q27
reference_count: 19
source_date: '2026-01-01'
title: Mental Models and Satisfaction
---


# Mental Models of AI Capabilities and Their Predictive Relationship with User Satisfaction and Continued Use


## Introduction

Understanding how users conceptualize artificial intelligence capabilities through their initial interactions represents a critical area of inquiry at the intersection of human-computer interaction, information systems, and cognitive psychology. Users' mental models—their internal representations of how AI systems function and what they can accomplish—are often revealed through their first prompts and initial engagement patterns. These mental models subsequently shape expectations, which in turn influence satisfaction and decisions regarding continued use,. This synthesis examines the theoretical frameworks and empirical evidence connecting users' initial AI conceptualizations to downstream behavioral outcomes.
  - Citations: Schneider (2025), Bhattacherjee (2001), Tian et al. (2024)


## Theoretical Foundations: Expectation-Confirmation and Mental Model Formation


### The Expectation-Confirmation Model in AI Contexts

The relationship between user expectations and continued technology use has been extensively theorized through the Expectation-Confirmation Model (ECM). Bhattacherjee's foundational work established that users' continuance intention is determined by their satisfaction with information system use and perceived usefulness of continued use, with satisfaction itself being influenced by confirmation of expectations from prior use. This framework has proven particularly applicable to AI systems, where initial mental models set the baseline for expectation formation.
  - Citations: Bhattacherjee (2001)

Research on AI chatbots in higher education has validated the ECM framework, demonstrating that users' perceived confirmation significantly influences their satisfaction and subsequent intention to continue using AI systems. The study by Tian et al. found that ECM constructs, particularly "Confirmation" and "Satisfaction," outweighed other factors in predicting user behavior, underscoring the critical role that initial expectations—shaped by mental models—play in determining continued engagement. Similarly, investigations into banking chatbot services have integrated the ECM with information systems success models, confirming that expectation confirmation drives continuance intentions.
  - Citations: Tian et al. (2024), Nguyen et al. (2021)


### Mental Model Shifts and Cognitive Transitions

Recent research has begun examining how mental models evolve through AI interaction. Schneider's analysis of over 200,000 conversations with large language models revealed that users increasingly adopt conversational behaviors typical of human-to-human communication, suggesting a cognitive transition in how users perceive and engage with AI systems. This finding indicates that first prompts may reveal initial mental models that subsequently shift as users gain experience, with implications for both satisfaction and continued use patterns. These insights highlight the dynamic nature of mental model formation and the need for research examining how initial conceptualizations predict longer-term outcomes.
  - Citations: Schneider (2025)


## The Role of Perceived Intelligence and Capability Assessment


### Intelligence Perceptions in First Interactions

Users' mental models of AI capabilities are fundamentally shaped by their perceptions of system intelligence, which are often established during initial interactions. Research on ChatGPT subscription intentions has demonstrated that perceived intelligence significantly influences user satisfaction and acceptance, reflecting the system's perceived capability to intelligently perform tasks. This perceived intelligence impacts both perceived ease of use and perceived usefulness, creating a foundation for continued engagement.
  - Citations: Jo (2024)

The assessment of AI intelligence and capability has been approached through standardized measurement instruments examining anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety. These dimensions collectively inform users' mental models and shape their expectations for system performance. When first prompts reveal sophisticated mental models aligned with actual AI capabilities, users are more likely to experience confirmation and subsequent satisfaction.
  - Citations: Bartneck et al. (2008), Bhattacherjee (2001)


### Cognitive Fit and Information Processing

From a cognitive fit perspective, user satisfaction with AI-generated content depends on the alignment between user expectations and system outputs. Yang et al. emphasize that understanding how users perceive and process AI-generated content is crucial for explaining satisfaction, noting that prior research consistently links user satisfaction with continuous usage intentions. When users' mental models—revealed through their initial prompting strategies—accurately reflect AI capabilities, cognitive fit is achieved, leading to higher satisfaction.
  - Citations: Yang et al. (2024)


## Factors Mediating the Mental Model-Satisfaction Relationship


### Perceived Usefulness and Ease of Use

The Technology Acceptance Model constructs of perceived usefulness and perceived ease of use remain central to understanding how mental models predict satisfaction. Research on AI implementation in fashion retail confirmed that consumers' evaluation of perceived usefulness and perceived ease of use significantly influence their attitude toward AI, which in turn affects expectations and satisfaction. Users whose first prompts demonstrate understanding of AI utility are better positioned to experience these positive perceptions.
  - Citations: Liang et al. (2019)

Studies examining AI-powered mobile speech recognition similarly found that perceived usefulness, perceived ease of use, and perceived enjoyment influence purchase intention through attitudes toward AI and consumer experience. The chain relationships identified in this research suggest that mental models shape initial perceptions, which cascade through attitudinal and experiential factors to influence continued use.
  - Citations: Arachchi (2023)


### Trust and Credibility Assessments

Trust represents a critical mediating factor between mental models and continued use. Research on voice-based AI systems has examined the drivers of consumer trust, noting that unique characteristics of AI technologies require broader perspectives beyond traditional technology acceptance frameworks. Users' mental models of AI capabilities influence their trust formation, which subsequently affects satisfaction and continued engagement.
  - Citations: Pitardi (2021)

The integration of trust factors with expectation-confirmation models has proven valuable in predicting chatbot continuance intentions. Nguyen et al. demonstrated that trust, combined with information systems success factors and expectation confirmation, determines users' intentions to continue using AI services. Mental models that appropriately calibrate AI trustworthiness lead to more sustainable usage patterns.
  - Citations: Nguyen et al. (2021)


### Emotional and Social Dimensions

Beyond purely functional assessments, users' mental models encompass emotional and social dimensions that influence satisfaction. Research on AI chatbots as brand promoters found that both intelligence quotient (IQ) and emotional quotient (EQ) factors explain consumers' interactant satisfaction. The multi-dimensional social support model helps explain how users' expectations of AI emotional capabilities—revealed through their interaction patterns—affect satisfaction outcomes.
  - Citations: Lee et al. (2021)

Studies on AI companions suggest that users who perceive companion bots as more conscious and human-like report more positive views and apparent social health benefits. This indicates that mental models incorporating social and emotional AI capabilities may predict different satisfaction patterns than purely task-oriented conceptualizations. Furthermore, research has shown that AI warmth and friendliness improve user satisfaction and perceptions of AI capability, although context determines the appropriateness of such characteristics.
  - Citations: Savic (2024), Rezwana (2025)


## Prompt Characteristics as Mental Model Indicators


### Content and Structure of Initial Prompts

The nature of users' first prompts provides insight into their mental models of AI capabilities. Research examining human-AI collaboration in writing scenarios found that users predominantly sent content-related prompts for data, facts, and information to ChatGPT, with affinity for technology integration positively associated with the frequency of complete text requests. These prompting patterns reveal users' conceptualizations of AI as information providers versus creative collaborators.
  - Citations: Luther et al. (2024)

The distinction between different prompt types reflects underlying mental models about AI capabilities. Users who approach AI systems with prompts aligned with system strengths—such as information retrieval versus creative generation—are more likely to experience satisfaction. Mixed-method analyses have shown that prior technology experience shapes prompting behavior, suggesting that mental models are influenced by broader technological literacy.
  - Citations: Luther et al. (2024)


### Task-Technology Fit Considerations

Research on conversational agents has examined how interaction modalities affect user experience across different task types. Rzepka et al. found that speech-based interaction exhibited higher perceived efficiency, lower cognitive effort, higher enjoyment, and higher service satisfaction than text-based interaction for information search tasks. This suggests that users' mental models must encompass not only AI capabilities but also appropriate interaction modalities for optimal satisfaction.
  - Citations: Rzepka et al. (2021)

The task-technology fit framework indicates that users whose mental models accurately match AI capabilities to appropriate tasks will experience greater satisfaction. First prompts that demonstrate understanding of suitable AI applications predict more positive outcomes than prompts reflecting misaligned expectations.
  - Citations: Rzepka et al. (2021)


## User Experience and Stickiness Outcomes


### Experience Quality and Retention

User experience significantly enhances user stickiness across various AI application scenarios and user types. Research on governmental chatbots found that experience quality influences retention independent of users' level of online participation, suggesting that mental model-experience alignment universally affects continued use. The integration of basic and advanced AI technologies influences user retention differently, indicating that mental models must evolve with technological capabilities.
  - Citations: Liu et al. (2025)

Human-Computer Interaction theory helps explain how users' experiences and satisfaction with AI tools impact their engagement and continued use. The cognitive, behavioral, and experiential factors influencing AI adoption are interconnected, with mental models serving as the cognitive foundation that shapes subsequent experiences.
  - Citations: Luthfi et al. (2025)


### Satisfaction as a Predictor of Continuance

The relationship between satisfaction and continued use has been consistently validated across AI contexts. Research confirms that keeping users satisfied with AI is crucial because user satisfaction is closely associated with continuous usage. Users whose initial mental models lead to confirmed expectations experience higher satisfaction, which in turn predicts stronger continuance intentions,.
  - Citations: Yang et al. (2024), Bhattacherjee (2001), Tian et al. (2024)

Studies on chatbot adoption in various industries have demonstrated that user satisfaction mediates the relationship between technology perceptions and behavioral intention. The examination of perceived accuracy, ease of use, completeness, and user satisfaction in predicting chatbot adoption confirms the central role of satisfaction in the mental model-continuance pathway.
  - Citations: Thaker (2025)


## Implications for AI Design and Interaction


### Designing for Mental Model Alignment

The findings synthesized here have significant implications for AI system design. Understanding that users' mental models predict satisfaction and continued use suggests that AI systems should be designed to facilitate accurate mental model formation. This includes providing appropriate feedback during initial interactions and managing user expectations through transparent capability communication.
  - Citations: Schneider (2025)

Research on AI communication frameworks emphasizes that improving user experience requires attention to how AI systems convey their capabilities and limitations. Warmth, friendliness, and human-like communication can foster positive user experiences but must be calibrated to context to avoid skepticism. Designers must consider how first interactions shape mental models and subsequent satisfaction trajectories.
  - Citations: Rezwana (2025)


### Ethical and Trust Considerations

The relationship between mental models and continued use raises ethical considerations regarding AI transparency and user autonomy. Research highlights the need for further investigation into how users cognitively frame their interactions with AI, particularly regarding trust and ethical concerns. Mental models that overestimate AI capabilities may lead to inappropriate reliance, while underestimation may prevent beneficial adoption.
  - Citations: Schneider (2025)

Studies on human-AI decision making emphasize that in high-stakes domains, understanding how mental models affect human-AI collaboration is crucial for safety and effectiveness. The growing interest in augmenting human decision making with AI assistance requires careful attention to how users conceptualize AI capabilities and limitations.
  - Citations: Lai et al. (2021)


## Conclusion

The evidence synthesized here demonstrates that users' mental models of AI capabilities, as revealed through first prompts and initial interactions, significantly predict satisfaction and continued use. The Expectation-Confirmation Model provides a robust theoretical framework for understanding this relationship, with confirmation of expectations emerging as a critical determinant of satisfaction,. Mental models shape perceptions of usefulness, ease of use, and intelligence, which cascade through attitudinal and experiential factors to influence continuance intentions,,.
  - Citations: Bhattacherjee (2001), Tian et al. (2024), Liang et al. (2019), Jo (2024), Arachchi (2023)

The dynamic nature of mental models—shifting through interaction experience—suggests that first prompts represent initial conceptualizations that evolve over time. Factors including trust, emotional engagement, and task-technology fit mediate the relationship between mental models and outcomes,,. For AI designers and researchers, these findings underscore the importance of facilitating accurate mental model formation and managing user expectations to promote sustainable, satisfying AI engagement,.
  - Citations: Schneider (2025), Pitardi (2021), Lee et al. (2021), Rzepka et al. (2021), Rezwana (2025), Liu et al. (2025)


## References

1. Arachchi, H. and Samarasinghe, D. (2023). Impact of embedded AI mobile smart speech recognition on consumer attitudes towards AI and purchase intention across Generations X and Y. *European Journal of Management Studies, 29(1), 3-29*.
2. Bartneck, C., Kulić, D., Croft, E., & Zoghbi, S. (2008). Measurement Instruments for the Anthropomorphism, Animacy, Likeability, Perceived Intelligence, and Perceived Safety of Robots. *International Journal of Social Robotics, 1(1), 71-81*.
3. Bhattacherjee, A. (2001). Understanding Information Systems Continuance: An Expectation-Confirmation Model1. *Mis Quarterly, 25(3), 351-370*.
4. Jo, H. (2024). Subscription intentions for ChatGPT plus: a look at user satisfaction and self-efficacy. *Marketing Intelligence & Planning, 42(6), 1052-1073*.
5. Lai, V., Chen, C., Liao, Q., Smith, A., & Tan, C. (2021). Towards a Science of Human-AI Decision Making: A Survey of Empirical Studies.
6. Lee, C., Pan, L., & Hsieh, S. (2021). Artificial intelligent chatbots as brand promoters: a two-stage structural equation modeling-artificial neural network approach. *Internet Research, 32(4), 1329-1356*.
7. Liang, Y., Lee, S., & Workman, J. (2019). Implementation of Artificial Intelligence in Fashion: Are Consumers Ready?. *Clothing and Textiles Research Journal, 38(1), 3-18*.
8. Liu, T., Guo, Y., Liu, S., Dong, P., & Chen, J. (2025). How Does User Experience Affect User Stickiness. *International Journal of Electronic Government Research, 21(1), 1-23*.
9. Luther, T., Kimmerle, J., & Creß, U. (2024). Teaming Up with an AI: Exploring Human–AI Collaboration in a Writing Scenario with ChatGPT. *Ai, 5(3), 1357-1376*.
10. Luthfi, Z., Prasetiyo, W., Sari, B., Waldi, A., & Muttaqiin, A. (2025). Dataset of AI adoption usage, expectations, attitudes, perceptions, and motivations for learning in higher education. *Data in Brief, 63, 112106*.
11. Nguyen, D., Chiu, Y., & Le, H. (2021). Determinants of Continuance Intention towards Banks’ Chatbot Services in Vietnam: A Necessity for Sustainable Development. *Sustainability, 13(14), 7625*.
12. Pitardi, V. and Marriott, H. (2021). Alexa, she's not human but… Unveiling the drivers of consumers' trust in voice‐based artificial intelligence. *Psychology and Marketing, 38(4), 626-642*.
13. Rezwana, J. and Ford, C. (2025). Improving User Experience with FAICO: Towards a Framework for AI Communication in Human-AI Co-Creativity., 1-9.
14. Rzepka, C., Berger, B., & Heß, T. (2021). Voice Assistant vs. Chatbot – Examining the Fit Between Conversational Agents’ Interaction Modalities and Information Search Tasks. *Information Systems Frontiers, 24(3), 839-856*.
15. Savic, M. (2024). Artificial Companions, Real Connections?. *M/C Journal, 27(6)*.
16. Schneider, J. (2025). Mental model shifts in human-LLM interactions. *Journal of Intelligent Information Systems, 63(5), 1737-1752*.
17. Thaker, H. (2025). Examining factors influencing chatbot adoption in Takaful industry: Malaysian evidence. *International Journal of Islamic and Middle Eastern Finance and Management*.
18. Tian, W., Ge, J., Zhao, Y., & Zheng, X. (2024). AI Chatbots in Chinese higher education: adoption, perception, and influence among graduate students—an integrated analysis utilizing UTAUT and ECM models. *Frontiers in Psychology, 15*.
19. Yang, B., Sun, Y., & Li, Q. (2024). To Be Credible or to Be Creative? Understanding the Antecedents of User Satisfaction with AI-Generated Content from a Cognitive Fit Perspective.